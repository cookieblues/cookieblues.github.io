I"	<p>The <a href="https://www.itu.dk/" target="_blank">IT University of Copenhagen (ITU)</a> conducts a student evaluation of the courses and the university itself each semester. The evaluations are one of the only ways that students can provide feedback to the lecturers, which can improve the learning environment, course material, exercises, and so on. The evaluations are also packed with interesting data, and naturally, as a data science student, I cannot keep my hands off them.<br />
This analysis of the evaluations will be a series of posts, where I’ll dive into some of the interesting data that we can get out of the evaluations. On top of that, these first few posts will serve as notes for the first project of the <a href="https://mit.itu.dk/ucs/cb_www/course.sml?course_id=2708256&amp;mode=search&amp;lang=en&amp;print_friendly_p=t&amp;goto=1547640286.000" target="_blank">First Year Project</a> course. This time we’ll focus on elementary <a href="https://en.wikipedia.org/wiki/Data_scraping" target="_blank">data scraping</a>, which in its broadest sense is the act of collecting data.</p>

<h3 id="browser-automation-with-selenium">Browser automation with Selenium</h3>
<p>To scrape data, firstly, we’ll need to find a place where our wanted data is located and free to use. Luckily, the ITU has made the evaluations publicly available on <a href="https://en.itu.dk/about-itu/organisation/facts-and-figures/quality-and-educational-environment/course-evaluation" target="_blank">their website</a>. Also, I spoke to someone at ITU, and they said that we can do anything we want with the evaluations, as long as the data is publicly available. So far, so good.<br />
Secondly, now we’ll have to come up with a way to actually collect the data. The link on ITU’s website leads to a webpage, where we can choose specific evaluation results for any evaluation period we desire. While the number of evaluation periods is small enough for us to manually collect the results, there are several benefits to not collecting the results this way. First of all, by avoiding performing a task the naive way we might learn something new. Second of all, if our method is broad enough, it might generalize to other tasks and save us time in the long run. Third of all, if we were to manually collect the results, the naive way would be to download the HTML pages, and afterwards clean the data for our purpose - however, we can clean the data as we collect it, if we don’t do it the naive way.<br />
Now, there are many ways to scrape data from websites, and depending on the specific website there might be a plethora of tools better suited for your purpose (public APIs, specific modules, etc.), especially if you want to scrape data from more popular sites. In this brief introduction to data scraping, we’ll utilize <a href="https://github.com/SeleniumHQ/Selenium" target="_blank">Selenium</a>, which is definitely not the most efficient library for browser automation, but we don’t have a lot of data to scrape, and we want something that is user-friendly.</p>
:ET