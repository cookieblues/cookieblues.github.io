I"
<p>Now we know a bit about machine learning: it involves models. Machine learning attempts to model data in order to make predictions about the data. In the <a href="http://localhost:4000/bsmalea-notes-1a">previous post</a> we dove into the inner functions of a model, and that is very much what machine learning is about. Yet, it’s only half of it, really. The other half has to do with the concept of prediction, and how we make sure our, model can predict well. This course doesn’t dabble that deep into this other half - but there are a few important topics in this regard, you should be aware of, as they pop up in machine learning all the time.</p>

<h3 id="model-selection-and-validation">Model selection and validation</h3>
<p>In the <a href="http://localhost:4000/bsmalea-notes-1a">previous post</a>, we went over polynomial regression. In the Python implementation, I chose to go with a polynomial of order $4$ (for no reason whatsoever). However, perhaps $M=4$ isn’t the ‘best’ choice - but what is the ‘best’ choice, and how do we find it? Firstly, the order of our polynomial is set before the training process begins, and we call these special parameters in our model <strong>“hyperparameters”</strong>. Secondly, the process of figuring out the values of the hyperparameters is called <strong>hyperparameter optimization</strong> and is a part of <strong>model selection</strong>. Thirdly, as mentioned in the <a href="http://localhost:4000/bsmalea-notes-1a">previous post</a>, machine learning is mostly concerned with prediction, which means that we define the ‘best’ model as the one that <strong>generalizes</strong> the best, i.e. which model would perform the best on data it wasn’t trained on?</p>

<p>To begin with, we usually want to come up with some kind of <strong>evaluation metric</strong> (which <em>can</em> be different from the objective function). Then we divide our training dataset into three: a <strong>training</strong>, a <strong>validation</strong> (sometimes called <strong>development</strong>), and a <strong>test</strong> dataset. Usually the new training dataset is $80\%$ of the original, and the validation and test datasets are $10\%$ each. Then we train our model on the training dataset, perform model selection on the validation dataset, and do a final evaluation of the model on the test dataset. This way, we can determine the model with the lowest <strong>generalization error</strong>. The generalization error refers to the performance of the model on <em>unseen data</em> (data it wasn’t trained on).</p>

:ET