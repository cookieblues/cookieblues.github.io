I"œ<p>This hopefully won‚Äôt take as long as my notes on <a href="http://localhost:4000/linear_algebra_and_optimisation">Linear Algebra and Optimization</a>, but I will start writing up my notes for the course ‚Äú<a href="https://mit.itu.dk/ucs/cb_www/course.sml?course_id=2013612&amp;mode=search&amp;lang=en&amp;print_friendly_p=t&amp;goto=1542111182.000" target="_blank">Machine Learning</a>‚Äù at the <a href="https://www.itu.dk/" target="_blank">IT University of Copenhangen</a>. My goal is as always to explain the intuition behind the introduced concepts, making it easier to understand and engage with. I believe this can help the few who struggle to understand the concepts, as well as found the concepts for those who know how to employ them but lack the why.</p>

<h3 id="overview">Overview</h3>
<p>If you click the link above, you‚Äôll see that there are four intended learning outcomes for the course; the student should be able to:</p>

<ul>
  <li><strong>Discuss</strong>, clearly <strong>explain</strong>, and <strong>reflect</strong> upon central machine learning concepts and algorithms.</li>
  <li><strong>Choose among</strong> and <strong>make use</strong> of the most important machine learning approaches in order to apply (match) them to practical problems.</li>
  <li><strong>Implement</strong> abstractly specified machine learning methods in an imperative programming language.</li>
  <li><strong>Combine</strong> and <strong>modify</strong> machine learning methods to <strong>analyse</strong> practical dataset and <strong>convey</strong> the results.</li>
</ul>

<!--more-->

<p>I believe, these can be summarized in a one-liner: the student should be able to <strong>comprehend</strong>, <strong>apply</strong>, and <strong>tweak</strong> machine learning methods, along with <strong>interpret</strong> the results to <strong>examine</strong> data. To elaborate on this a bit, the course is about understanding mathematical formulations of machine learning methods and programming them, which is why I‚Äôll try to incorporate code snippets into these notes. It‚Äôs important to stress that the course is not a course in any specific machine learning library like TensorFlow, it‚Äôs not about deep learning, and it‚Äôs not about deriving models mathematically.</p>

<p>Both statistics and linear algebra are prerequisites for machine learning. Not every little theorem is important, but the overall understanding and ability to use tools from statistics and linear algebra will be immensely helpful. Luckily, the course starts out with an introductory week, where the basics of machine learning are explained and a bit of probability theory is revised.<br />
Underneath is an overview of the notes, I‚Äôll be writing. They more or less follow the structure of the course.</p>

<ol>
  <li>Introduction to machine learning:<br />
 (a) <a href="http://localhost:4000/bsmalea-notes-1a">What is machine learning?</a><br />
 (b) <a href="http://localhost:4000/bsmalea-notes-1b">Model selection and validation, the ‚Äúno free lunch‚Äù theorem, and the curse of dimensionality</a><br />
 (c) Frequentism and Bayesianism<br />
 (d) Decision and information theory</li>
  <li><a href="http://localhost:4000/bsmalea-notes-2">Regression</a></li>
  <li>Classification:<br />
 (a) Overview of classifiers<br />
 (b) Distribution-free models<br />
 (c) Discriminative models (logistic regression)<br />
 (d) Generative models</li>
  <li>Neural networks (feed-forward, backprop)</li>
  <li>SVM (SMO), kernel methods</li>
  <li>Graphical models</li>
  <li>Mixture models and expectation-maximization (EM)</li>
  <li>Sequential data (HMM)</li>
  <li>Dimensionality reduction (LDA), continuous latent variables (PCA)</li>
  <li>Combining models (ensemble methods, AdaBoost)</li>
</ol>
:ET